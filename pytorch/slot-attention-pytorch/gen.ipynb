{"cells":[{"cell_type":"code","execution_count":53,"id":"16d6e2c3","metadata":{},"outputs":[],"source":["import clip\n","import math\n","from tqdm.notebook import tqdm\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torch.utils.data as data\n","\n","\n","def train(model, train_loader, z_loader, optimizer, scheduler, model_depth):\n","    model.train()\n","    train_losses = []\n","    for (x, y), z in tqdm(zip(train_loader, z_loader), total=len(train_loader)):\n","        # batch = [b.cuda() for b in batch]\n","        # print(batch)\n","        # print(*batch)\n","        loss = model.loss(x, y, z, model_depth)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        train_losses.append(loss.item())\n","    return train_losses\n","\n","\n","@torch.no_grad()\n","def eval_loss(model, data_loader, model_depth):\n","    model.eval()\n","    total_loss, total = 0, 0\n","    for batch in data_loader:\n","        batch = [b.cuda() for b in batch]\n","        loss = model.loss(*batch, model_depth)\n","        total_loss += loss.item() * batch[0].shape[0]\n","        total += batch[0].shape[0]\n","    avg_loss = total_loss / total\n","    return avg_loss\n","\n","\n","def get_lr(step, total_steps, warmup_steps, use_cos_decay):\n","    if step < warmup_steps:\n","        mul = (step + 1) / warmup_steps\n","        return mul\n","    else:\n","        if use_cos_decay:\n","            progress = (step - warmup_steps) / (total_steps - warmup_steps)\n","            return (1 + math.cos(math.pi * progress)) / 2\n","        else:\n","            return 1\n","\n","\n","def train_epochs(model, train_loader, test_loader, z_loader, train_args):\n","    epochs, lr = train_args[\"epochs\"], train_args[\"lr\"]\n","    warmup_steps = train_args.get(\"warmup\", 0)\n","    use_cos_decay = train_args.get(\"use_cos_decay\", False)\n","    optimizer = optim.Adam(model.parameters(), lr)\n","    total_steps = epochs * len(train_loader)\n","    scheduler = optim.lr_scheduler.LambdaLR(\n","        optimizer,\n","        lr_lambda=lambda step: get_lr(step, total_steps, warmup_steps, use_cos_decay),\n","    )\n","\n","    train_losses = []\n","    # test_losses = [eval_loss(model, test_loader)]\n","    for epoch in tqdm(list(range(epochs))):\n","        train_loss = train(\n","            model,\n","            train_loader,\n","            z_loader,\n","            optimizer,\n","            scheduler,\n","            train_args[\"model_depth\"],\n","        )\n","        train_losses.extend(train_loss)\n","        # test_loss = eval_loss(model, test_loader)\n","        test_losses.append(test_loss)\n","        print(\n","            f\"Epoch {epoch}, Test loss {test_loss:.4f}, Train loss {np.mean(train_loss):.4f}\"\n","        )\n","\n","    return np.array(train_losses)  # , np.array(test_losses)\n","\n","\n","class Diffusion:\n","    def __init__(self, model, data_shape, encode_fn=None, decode_fn=None):\n","        self.model = model\n","        self.data_shape = data_shape\n","        self.encode_fn = encode_fn\n","        self.decode_fn = decode_fn\n","        self.clip, self.transform = clip.load(\"ViT-B/32\", device=\"cuda\")\n","\n","    def _get_alpha_sigma(self, t):\n","        return torch.cos(t * math.pi / 2), torch.sin(t * math.pi / 2)\n","\n","    def _expand(self, t):\n","        for _ in range(len(self.data_shape)):\n","            t = t[..., None]\n","        return t\n","\n","    def _noise(self, x, eps=None, t=None):\n","        if t is None:\n","            t = torch.rand(x.shape[0], dtype=torch.float32, device=x.device)\n","        if eps is None:\n","            eps = torch.randn_like(x)\n","        alpha_t, sigma_t = self._get_alpha_sigma(self._expand(t))\n","        x_t = alpha_t * x + sigma_t * eps\n","        return x_t, eps, t\n","\n","    def _x_hat(self, x_t, eps_hat, t):\n","        alpha_t, sigma_t = self._get_alpha_sigma(self._expand(t))\n","        return (x_t - sigma_t * eps_hat) / alpha_t\n","\n","    def loss(self, x, y=None, z=None, model_depth=0):\n","        z = x if model_depth == 0 else z\n","        # if self.encode_fn is not None:\n","        #     x = self.encode_fn(x)\n","        print(\"in loss\")\n","        print(x)\n","        print(y)\n","        print(z)\n","        print(model_depth)\n","        print(x.shape)\n","        print(y.shape)\n","        y = self.clip.encode_text(y)\n","        x_t, eps, t = self._noise(x)\n","        if y is not None:\n","            eps_hat = self.model.forward_step(x_t, y, t, model_depth)\n","        else:\n","            eps_hat = self.model.forward_step(x_t, t, model_depth)\n","        return torch.mean((eps_hat - eps) ** 2)\n","\n","    @torch.no_grad()\n","    def sample(self, n, num_steps, clip_denoised=False, model_fn=None, cfg_val=None):\n","        model_fn = model_fn or self.model\n","\n","        ts = np.linspace(1 - 1e-4, 1e-4, num_steps + 1, dtype=np.float32)\n","        x = torch.randn(n, *self.data_shape, dtype=torch.float32).cuda()\n","        for i in range(num_steps):\n","            t_cur = torch.full((n,), ts[i], dtype=torch.float32).cuda()\n","            t_next = torch.full((n,), ts[i + 1], dtype=torch.float32).cuda()\n","\n","            alpha_cur, sigma_cur = self._get_alpha_sigma(self._expand(t_cur))\n","            alpha_next, sigma_next = self._get_alpha_sigma(self._expand(t_next))\n","            ddim_sigma = (sigma_next / sigma_cur) * torch.sqrt(\n","                1 - alpha_cur**2 / alpha_next**2\n","            )\n","\n","            if cfg_val is None:\n","                eps_hat = model_fn(x, t_cur)\n","            else:\n","                eps_hat_cond = model_fn(x, t_cur)\n","                eps_hat_uncond = model_fn(x, t_cur, dropout_cond=True)\n","                eps_hat = eps_hat_uncond + cfg_val * (eps_hat_cond - eps_hat_uncond)\n","\n","            x_hat = self._x_hat(x, eps_hat, t_cur)\n","            if clip_denoised:\n","                x_hat = torch.clamp(x_hat, -1, 1)\n","            x = (\n","                alpha_next * x_hat\n","                + torch.sqrt((sigma_next**2 - ddim_sigma**2).clamp(min=0)) * eps_hat\n","                + ddim_sigma * torch.randn_like(eps_hat)\n","            )\n","        # if self.decode_fn is not None:\n","        #     x = self.decode_fn(x)\n","        return x\n","\n","    def __getattr__(self, name):\n","        if name in [\"train\", \"eval\", \"parameters\", \"state_dict\", \"load_state_dict\"]:\n","            return getattr(self.model, name)\n","        return self.__getattribute__(name)\n","\n","\n","class MLP(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, n_hidden_layers, timestep_dim=1):\n","        super().__init__()\n","        self.timestep_dim = timestep_dim\n","        prev_dim = input_dim + timestep_dim\n","        net = []\n","        dims = [hidden_dim] * n_hidden_layers + [input_dim]\n","        for i, dim in enumerate(dims):\n","            net.append(nn.Linear(prev_dim, dim))\n","            if i < len(dims) - 1:\n","                net.append(nn.ReLU())\n","            prev_dim = dim\n","        self.net = nn.Sequential(*net)\n","\n","    def forward(self, x, t):\n","        x = torch.cat([x, t[:, None]], dim=1)\n","        return self.net(x)"]},{"cell_type":"code","execution_count":54,"id":"d7d20590","metadata":{"id":"d7d20590"},"outputs":[],"source":["# !if [ -d deepul ]; then rm -Rf deepul; fi\n","# !git clone https://github.com/rll/deepul.git\n","# !pip install ./deepul\n","# !pip install scikit-learn"]},{"cell_type":"code","execution_count":55,"id":"3f55a3dd","metadata":{"id":"3f55a3dd"},"outputs":[],"source":["from deepul.hw4_helper import *\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":56,"id":"6126dbe7","metadata":{"id":"6126dbe7"},"outputs":[],"source":["def timestep_embedding(timesteps, dim, max_period=10000):\n","    half = dim // 2\n","    freqs = torch.exp(\n","        -math.log(max_period) * torch.arange(0,\n","                                             half, dtype=torch.float32) / half\n","    ).cuda()\n","    args = timesteps[:, None].float() * freqs[None]\n","    embedding = torch.cat([torch.cos(args), torch.sin(args)], axis=-1)\n","    if dim % 2:\n","        embedding = torch.cat(\n","            [embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n","    return embedding\n","\n","\n","class Attention(nn.Module):\n","    def __init__(self, hidden_size, num_heads):\n","        super().__init__()\n","        self.num_heads = num_heads\n","        self.wq = nn.Linear(hidden_size, hidden_size, bias=False)\n","        self.wk = nn.Linear(hidden_size, hidden_size, bias=False)\n","        self.wv = nn.Linear(hidden_size, hidden_size, bias=False)\n","        self.wo = nn.Linear(hidden_size, hidden_size, bias=False)\n","\n","    def forward(self, x):\n","        q, k, v = self.wq(x), self.wk(x), self.wv(x)\n","        q, k, v = map(lambda x: x.view(\n","            *x.shape[:-1], self.num_heads, -1), (q, k, v))\n","        attn_weights = torch.einsum(\n","            \"bqhd,bkhd->bhqk\", q, k) * q.shape[-1] ** -0.5\n","        attn_weights = F.softmax(attn_weights, dim=-1)\n","        attn_outputs = torch.einsum(\"bhqk,bkhd->bqhd\", attn_weights, v)\n","        attn_outputs = attn_outputs.reshape(*attn_outputs.shape[:-2], -1)\n","        return self.wo(attn_outputs)\n","\n","\n","class MLP(nn.Module):\n","    def __init__(self, hidden_size, expand=4):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(hidden_size, hidden_size * expand),\n","            nn.SiLU(),\n","            nn.Linear(hidden_size * expand, hidden_size),\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","\n","def modulate(x, shift, scale):\n","    return x * (1 + scale.unsqueeze(1)) + shift.unsqueeze(1)\n","\n","\n","def get_2d_sincos_pos_embed_from_grid(embed_dim, grid):\n","    assert embed_dim % 2 == 0\n","\n","    # use half of dimensions to encode grid_h\n","    emb_h = get_1d_sincos_pos_embed_from_grid(\n","        embed_dim // 2, grid[0])  # (H*W, D/2)\n","    emb_w = get_1d_sincos_pos_embed_from_grid(\n","        embed_dim // 2, grid[1])  # (H*W, D/2)\n","\n","    emb = np.concatenate([emb_h, emb_w], axis=1)  # (H*W, D)\n","    return emb\n","\n","\n","def get_1d_sincos_pos_embed_from_grid(embed_dim, pos):\n","    assert embed_dim % 2 == 0\n","    omega = np.arange(embed_dim // 2, dtype=np.float64)\n","    omega /= embed_dim / 2.0\n","    omega = 1.0 / 10000**omega  # (D/2,)\n","\n","    pos = pos.reshape(-1)  # (M,)\n","    out = np.einsum(\"m,d->md\", pos, omega)  # (M, D/2), outer product\n","\n","    emb_sin = np.sin(out)  # (M, D/2)\n","    emb_cos = np.cos(out)  # (M, D/2)\n","\n","    emb = np.concatenate([emb_sin, emb_cos], axis=1)  # (M, D)\n","    return emb\n","\n","\n","def get_2d_sincos_pos_embed(embed_dim, grid_size):\n","    grid_h = np.arange(grid_size, dtype=np.float32)\n","    grid_w = np.arange(grid_size, dtype=np.float32)\n","    grid = np.meshgrid(grid_w, grid_h)  # here w goes first\n","    grid = np.stack(grid, axis=0)\n","\n","    grid = grid.reshape([2, 1, grid_size, grid_size])\n","    pos_embed = get_2d_sincos_pos_embed_from_grid(embed_dim, grid)\n","    return pos_embed\n","\n","\n","class DiTBlock(nn.Module):\n","    def __init__(self, hidden_size, num_heads):\n","        super().__init__()\n","        self.attention = Attention(hidden_size, num_heads)\n","        self.mlp = MLP(hidden_size)\n","        self.attention_norm = nn.LayerNorm(\n","            hidden_size, elementwise_affine=False)\n","        self.mlp_norm = nn.LayerNorm(hidden_size, elementwise_affine=False)\n","        self.adaLN_modulation = nn.Sequential(\n","            nn.SiLU(), nn.Linear(hidden_size, 6 * hidden_size)\n","        )\n","\n","    def forward(self, x, c):\n","        shift_msa, scale_msa, gate_msa, shift_mlp, scale_mlp, gate_mlp = (\n","            self.adaLN_modulation(c).chunk(6, dim=1)\n","        )\n","        x = x + gate_msa.unsqueeze(1) * self.attention(\n","            modulate(self.attention_norm(x), shift_msa, scale_msa)\n","        )\n","        x = x + gate_mlp.unsqueeze(1) * self.mlp(\n","            modulate(self.mlp_norm(x), shift_mlp, scale_mlp)\n","        )\n","        return x\n","\n","\n","class FinalLayer(nn.Module):\n","    def __init__(self, hidden_size, patch_size, out_channels):\n","        super().__init__()\n","        self.norm_final = nn.LayerNorm(\n","            hidden_size, elementwise_affine=False, eps=1e-6)\n","        self.linear = nn.Linear(\n","            hidden_size, patch_size * patch_size * out_channels, bias=True\n","        )\n","        self.adaLN_modulation = nn.Sequential(\n","            nn.SiLU(), nn.Linear(hidden_size, 2 * hidden_size, bias=True)\n","        )\n","\n","    def forward(self, x, c):\n","        shift, scale = self.adaLN_modulation(c).chunk(2, dim=1)\n","        x = modulate(self.norm_final(x), shift, scale)\n","        x = self.linear(x)\n","        return x\n","\n","\n","class DiT(nn.Module):\n","    def __init__(\n","        self,\n","        input_shape,\n","        patch_size,\n","        hidden_size,\n","        num_heads,\n","        num_layers,\n","        num_classes=10,\n","        frequency_embedding_size=64,\n","        cfg_dropout_prob=0.1,\n","    ):\n","        super().__init__()\n","        self.cfg_dropout_prob = cfg_dropout_prob\n","        self.frequency_embedding_size = frequency_embedding_size\n","        self.num_classes = num_classes\n","        self.input_shape = input_shape\n","        self.patch_size = patch_size\n","\n","        self.time_embedding = nn.Sequential(\n","            nn.Linear(frequency_embedding_size, hidden_size),\n","            nn.SiLU(),\n","            nn.Linear(hidden_size, hidden_size),\n","        )\n","        # batch_size, num_blocks, hidden_size\n","        self.label_embedder = nn.Embedding(num_classes + 1, hidden_size)\n","\n","        C, H, W = input_shape\n","        n_patches = (H // patch_size) * (W // patch_size)\n","        self.patchify = nn.Conv2d(\n","            C, hidden_size, patch_size, stride=patch_size)\n","        self.register_buffer(\n","            \"pos_embed\",\n","            torch.FloatTensor(get_2d_sincos_pos_embed(\n","                hidden_size, H // patch_size)),\n","        )\n","        self.blocks = nn.ModuleList(\n","            [DiTBlock(hidden_size, num_heads) for _ in range(num_layers)]\n","        )\n","        self.out_layer = FinalLayer(hidden_size, patch_size, C)\n","\n","    def unpatchify(self, x):\n","        C, H, W = self.input_shape\n","        P = self.patch_size\n","        x = x.view(x.shape[0], H // P, W // P, P, P, C)\n","        x.shape[0], H // P, P, W // P, P, C\n","        x = x.permute(0, 5, 1, 3, 2, 4).contiguous()\n","        x = x.view(x.shape[0], C, H, W)\n","        return x\n","\n","    def forward(self, x, y, t):\n","        # x: BCHW\n","        x = self.patchify(x).movedim(1, -1)\n","        x = x.reshape(x.shape[0], -1, x.shape[-1])\n","        x = x + self.pos_embed\n","\n","        t = self.time_embedding(timestep_embedding(\n","            t, self.frequency_embedding_size))\n","        if self.training:\n","            drop_ids = torch.rand(\n","                y.shape[0], device=y.device) < self.cfg_dropout_prob\n","            y = torch.where(drop_ids, self.num_classes, y)\n","        y = self.label_embedder(y)\n","        c = t + y\n","        for block in self.blocks:\n","            x = block(x, c)\n","        x = self.out_layer(x, c)\n","        return self.unpatchify(x)"]},{"cell_type":"code","execution_count":57,"id":"dd0f4aa2","metadata":{},"outputs":[],"source":["import clip\n","import os\n","import sys\n","import torch\n","\n","sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../../data\")))\n","\n","\n","def load_q3_data():\n","    import multimnist\n","\n","    ds = 1000\n","    images_train, text_descs_train = multimnist.generate(ds)\n","    images_test, text_descs_test = multimnist.generate(ds)\n","    text_descs_train = torch.cat(\n","        [clip.tokenize(txt).to(\"cuda\") for txt in text_descs_train]\n","    )\n","    text_descs_test = torch.cat(\n","        [clip.tokenize(txt).to(\"cuda\") for txt in text_descs_test]\n","    )\n","    train_data = {\"images\": images_train, \"texts\": text_descs_train}\n","    test_data = {\"images\": images_test, \"texts\": text_descs_test}\n","    return train_data, test_data\n","    # return dataset[:500], dataset[500:]\n","    # train_data = torchvision.datasets.CIFAR10(\n","    #     \"./data\", transform=torchvision.transforms.ToTensor(), download=True, train=True\n","    # )\n","    # test_data = torchvision.datasets.CIFAR10(\n","    #     \"./data\",\n","    #     transform=torchvision.transforms.ToTensor(),\n","    #     download=True,\n","    #     train=False,\n","    # )\n","    # return train_data, test_data\n","\n","\n","def show_samples(\n","    samples: np.ndarray, fname: str = None, nrow: int = 10, title: str = \"Samples\"\n","):\n","    import torch\n","    from torchvision.utils import make_grid\n","\n","    samples = (torch.FloatTensor(samples) / 255).permute(0, 3, 1, 2)\n","    grid_img = make_grid(samples, nrow=nrow)\n","    plt.figure()\n","    plt.title(title)\n","    plt.imshow(grid_img.permute(1, 2, 0))\n","    plt.axis(\"off\")\n","\n","    if fname is not None:\n","        savefig(fname)\n","    else:\n","        plt.show()"]},{"cell_type":"code","execution_count":58,"id":"edfdfaa3","metadata":{},"outputs":[],"source":["# Hyperparameters.\n","seed = 0\n","batch_size = 1  # wondering trained on some fixed slot makes difference\n","num_slots = 7\n","num_iterations = 3\n","hid_dim = 64\n","resolution = (128, 128)\n","online = False\n","results_dir = \"/shared/rzhang/slot_att/results/full-token-compressor\"\n","model_name = \"dummy\""]},{"cell_type":"code","execution_count":59,"id":"891156e0","metadata":{"id":"891156e0"},"outputs":[],"source":["from model import *\n","import wandb\n","from glob import glob\n","\n","\n","def q3_b(train_data, train_texts, test_data, test_texts, vae):\n","    \"\"\"\n","    train_data: A (50000, 32, 32, 3) numpy array of images in [0, 1]\n","    train_labels: A (50000,) numpy array of class labels\n","    test_data: A (10000, 32, 32, 3) numpy array of images in [0, 1]\n","    test_labels: A (10000,) numpy array of class labels\n","    vae: a pretrained VAE\n","\n","    Returns\n","    - a (# of training iterations,) numpy array of train losses evaluated every minibatch\n","    - a (# of num_epochs + 1,) numpy array of test losses evaluated at the start of training and the end of every epoch\n","    - a numpy array of size (10, 10, 32, 32, 3) of samples in [0, 1] drawn from your model.\n","      The array represents a 10 x 10 grid of generated samples. Each row represents 10 samples generated\n","      for a specific class (i.e. row 0 is class 0, row 1 class 1, ...). Use 512 diffusion timesteps\n","    \"\"\"\n","    # train_data = 2 * np.transpose(train_data, (0, 3, 1, 2)) - 1\n","    # test_data = 2 * np.transpose(test_data, (0, 3, 1, 2)) - 1\n","    image_data = torch.FloatTensor(train_data)\n","    train_data = data.TensorDataset(torch.FloatTensor(train_data), train_texts)\n","    test_data = data.TensorDataset(torch.FloatTensor(test_data), test_texts)\n","    train_loader = data.DataLoader(train_data, batch_size=256, shuffle=True)\n","    test_loader = data.DataLoader(train_data, batch_size=256)\n","    z_dataloader = data.DataLoader(\n","        torch.ones(len(train_data)).to(\"cpu\"), batch_size=batch_size, shuffle=True\n","    )\n","\n","    scale_factor = 1.3101\n","\n","    def encode_fn(x):\n","        z = vae.encode(x)\n","        z /= scale_factor\n","        return z\n","\n","    def decode_fn(z):\n","        z *= scale_factor\n","        x = vae.decode(z)\n","        return x\n","\n","    resolution = (128, 128)\n","    model_slotattention = SlotAttentionAutoEncoder(\n","        resolution,\n","        num_slots,\n","        num_iterations,\n","        hid_dim,\n","        cnn_depth=4,\n","        use_trfmr=False,\n","        use_transformer_encoder=False,\n","        use_transformer_decoder=False,\n","    ).to(device)\n","    model_direct = SlotAttentionCompressionAutoencoderDirect(\n","        model_slotattention, num_slots, hid_dim\n","    ).to(device)\n","    model = SlotAttentionCompressionDiffusion(model_direct, hid_dim).to(device)\n","    image_shape = (3, 128, 128)\n","    # DiT((4, 8, 8), patch_size=2, hidden_size=512, num_heads=8, num_layers=12).cuda()\n","    model = Diffusion(model, image_shape,\n","                      encode_fn=encode_fn, decode_fn=decode_fn)\n","\n","    for model_depth in range(num_slots):\n","        # Make results folder (holds all experiment subfolders)\n","        if online:\n","            os.makedirs(results_dir, exist_ok=True)\n","            exp_index = len(glob(f\"{results_dir}/*\"))\n","            model_filename = f\"{exp_index:03d}-{model_name}-slots{num_slots}-layer{num_slots-model_depth}-\"\n","            wandb.init(\n","                dir=os.path.abspath(results_dir),\n","                project=f\"slot_att_pretrained\",\n","                name=model_filename,\n","                job_type=\"train\",\n","                mode=\"online\",\n","            )\n","            torch.save(\n","                {\n","                    \"model_state_dict\": model.state_dict(),\n","                },\n","                results_dir + f\"/{model_filename}.ckpt\",\n","            )\n","\n","        train_losses = train_epochs(\n","            model,\n","            train_loader,\n","            test_loader,  # TODO: use z_dataloader,\n","            z_dataloader,\n","            dict(\n","                epochs=20,\n","                lr=1e-3,\n","                warmup=100,\n","                use_cos_decay=True,\n","                model_depth=model_depth,\n","            ),\n","        )\n","        test_losses = None\n","\n","        # we want to replace the dataloader with the compressed data\n","        z_new = []\n","        with torch.no_grad():\n","            model.eval()\n","            for (image, text), z in tqdm(\n","                zip(train_loader, z_dataloader), total=len(z_dataloader)\n","            ):\n","                z = x[\"image\"].to(device) if model_depth == 0 else z.to(device)\n","                z_fwd = model.get_compressed(z, model_depth).detach().clone()\n","                z_new.append(z_fwd)\n","            z_new = torch.cat(z_new, dim=0).cpu()\n","\n","        # train_data = data.TensorDataset(z_new, train_texts, image_data)\n","        z_dataloader = torch.utils.data.DataLoader(\n","            z_new, batch_size=batch_size, shuffle=True\n","        )\n","\n","        if online:\n","            torch.save(\n","                {\n","                    \"model_state_dict\": model.state_dict(),\n","                },\n","                opt.results_dir + f\"/{model_filename}.ckpt\",\n","            )\n","            wandb.finish()\n","\n","    # torch.save(model.state_dict(), \"q3_model.pt\")\n","\n","    text = \"dummy\"\n","    text_emb = clip.tokenize(text).cuda()\n","\n","    # def model_fn(x, t):\n","    #     return model.model(x, text_emb, t)\n","\n","    # samples = model.sample(\n","    #     labels.shape[0], 512, clip_denoised=False, model_fn=model_fn)\n","    samples = samples.movedim(1, -1).cpu().numpy()\n","    samples = samples * 0.5 + 0.5\n","    samples = samples.reshape(10, 10, *samples.shape[1:])\n","    return train_losses, test_losses, samples\n","\n","\n","# import os\n","# def get_data_dir(hw_number: int):\n","#     return os.path.join(\"deepul\", \"homeworks\", f\"hw{hw_number}\", \"data\")\n","\n","\n","# def load_pretrain_vae():\n","#     data_dir = get_data_dir(4)\n","#     vae = VAE()\n","#     vae.load_state_dict(torch.load(os.path.join(data_dir, f\"vae_cifar10.pth\")))\n","#     vae.eval()\n","#     return vae.cuda()"]},{"cell_type":"code","execution_count":60,"id":"2cd97002","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Creating MultiMNIST dataset...\n"]},{"name":"stderr","output_type":"stream","text":[" 73%|███████▎  | 733/1000 [00:00<00:00, 1251.19it/s]"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [00:00<00:00, 1231.25it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Creating MultiMNIST dataset...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [00:00<00:00, 1233.99it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6316d54126aa4f12a7037a9f4d072457","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"80f9c7635bf3494aa7acc56fce8b4311","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["in loss\n","tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         ...,\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n","\n","\n","        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         ...,\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n","\n","\n","        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         ...,\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n","\n","\n","        ...,\n","\n","\n","        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         ...,\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n","\n","\n","        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         ...,\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n","\n","\n","        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         ...,\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]]]])\n","tensor([[49406,   320,   271,  ...,     0,     0,     0],\n","        [49406,   320,   271,  ...,     0,     0,     0],\n","        [49406,   320,   271,  ...,     0,     0,     0],\n","        ...,\n","        [49406,   320,   271,  ...,     0,     0,     0],\n","        [49406,   320,   271,  ...,     0,     0,     0],\n","        [49406,   320,   271,  ...,     0,     0,     0]], device='cuda:0',\n","       dtype=torch.int32)\n","tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         ...,\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n","\n","\n","        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         ...,\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n","\n","\n","        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         ...,\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n","\n","\n","        ...,\n","\n","\n","        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         ...,\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n","\n","\n","        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         ...,\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n","\n","\n","        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         ...,\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]],\n","\n","         [[-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.],\n","          [-1., -1., -1.,  ..., -1., -1., -1.]]]])\n","0\n","torch.Size([256, 128, 3, 128])\n","torch.Size([256, 77])\n"]},{"ename":"TypeError","evalue":"forward_step() takes 3 positional arguments but 5 were given","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[60], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m test_images \u001b[38;5;241m=\u001b[39m test_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[1;32m      8\u001b[0m vae \u001b[38;5;241m=\u001b[39m load_pretrain_vae()\n\u001b[0;32m----> 9\u001b[0m train_losses, test_losses, samples \u001b[38;5;241m=\u001b[39m \u001b[43mq3_b\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtexts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtexts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvae\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal Test Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_losses[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m save_training_plot(\n\u001b[1;32m     15\u001b[0m     train_losses, test_losses, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ3(b) Train Plot\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/q3_b_train_plot.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m )\n","Cell \u001b[0;32mIn[59], line 83\u001b[0m, in \u001b[0;36mq3_b\u001b[0;34m(train_data, train_texts, test_data, test_texts, vae)\u001b[0m\n\u001b[1;32m     69\u001b[0m     wandb\u001b[38;5;241m.\u001b[39minit(\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;28mdir\u001b[39m\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(results_dir),\n\u001b[1;32m     71\u001b[0m         project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslot_att_pretrained\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m         mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     75\u001b[0m     )\n\u001b[1;32m     76\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(\n\u001b[1;32m     77\u001b[0m         {\n\u001b[1;32m     78\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m: model\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m     79\u001b[0m         },\n\u001b[1;32m     80\u001b[0m         results_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     81\u001b[0m     )\n\u001b[0;32m---> 83\u001b[0m train_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epochs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# TODO: use z_dataloader,\u001b[39;49;00m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mz_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarmup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cos_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_depth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m test_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# we want to replace the dataloader with the compressed data\u001b[39;00m\n","Cell \u001b[0;32mIn[53], line 67\u001b[0m, in \u001b[0;36mtrain_epochs\u001b[0;34m(model, train_loader, test_loader, z_loader, train_args)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# test_losses = [eval_loss(model, test_loader)]\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(epochs))):\n\u001b[0;32m---> 67\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43mz_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_depth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mextend(train_loss)\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m# test_loss = eval_loss(model, test_loader)\u001b[39;00m\n","Cell \u001b[0;32mIn[53], line 18\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, z_loader, optimizer, scheduler, model_depth)\u001b[0m\n\u001b[1;32m     13\u001b[0m train_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (x, y), z \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mzip\u001b[39m(train_loader, z_loader), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader)):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# batch = [b.cuda() for b in batch]\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# print(batch)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# print(*batch)\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_depth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     20\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n","Cell \u001b[0;32mIn[53], line 128\u001b[0m, in \u001b[0;36mDiffusion.loss\u001b[0;34m(self, x, y, z, model_depth)\u001b[0m\n\u001b[1;32m    126\u001b[0m x_t, eps, t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_noise(x)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 128\u001b[0m     eps_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_depth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    130\u001b[0m     eps_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mforward_step(x_t, t, model_depth)\n","\u001b[0;31mTypeError\u001b[0m: forward_step() takes 3 positional arguments but 5 were given"]}],"source":["from torchvision.utils import make_grid\n","import torch\n","\n","# opt = parse_args()\n","train_data, test_data = load_q3_data()\n","train_images = train_data[\"images\"] / 255.0\n","test_images = test_data[\"images\"] / 255.0\n","vae = load_pretrain_vae()\n","train_losses, test_losses, samples = q3_b(\n","    train_images, train_data[\"texts\"], test_images, test_data[\"texts\"], vae\n",")\n","\n","print(f\"Final Test Loss: {test_losses[-1]:.4f}\")\n","save_training_plot(\n","    train_losses, test_losses, \"Q3(b) Train Plot\", \"results/q3_b_train_plot.png\"\n",")\n","\n","samples = samples.reshape(-1, *samples.shape[2:])\n","show_samples(\n","    samples * 255.0,\n","    fname=f\"results/q3_b_samples.png\",\n","    title=f\"Q3(b) CIFAR-10 generated samples\",\n",")"]},{"cell_type":"code","execution_count":null,"id":"5a44c3a5","metadata":{},"outputs":[],"source":["# q3b_save_results(q3_b)"]},{"cell_type":"code","execution_count":null,"id":"babdae05","metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n","\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n","\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["import os\n","\n","os._exit(00)"]},{"cell_type":"code","execution_count":null,"id":"871aed9f","metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":5}
